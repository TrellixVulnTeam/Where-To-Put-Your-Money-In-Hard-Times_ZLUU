import warnings
warnings.filterwarnings('ignore')
import yfinance as yf
from pathlib import Path
import numpy as np
import pandas as pd
import pandas_datareader.data as web
from scipy.stats import spearmanr
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow import keras
import matplotlib.pyplot as plt
import seaborn as sns
gpu_devices = tf.config.experimental.list_physical_devices('GPU')
if gpu_devices:
    print('Using GPU')
    tf.config.experimental.set_memory_growth(gpu_devices[0], True)
else:
    print('Using CPU')
sns.set_style('whitegrid')
np.random.seed(42)
results_path = Path('results', 'univariate_time_series')
if not results_path.exists():
    results_path.mkdir(parents=True)

class Univariate_TS_Reg:
    def __init__(self, ticker):
        self.ticker = ticker

    def runs(self):
        sp500 = yf.download(self.ticker, period='10y', interval='1mo')['Adj Close']
        sp500 = pd.DataFrame(sp500)
        sp500.columns = ['SP500']
        ax = sp500.plot(title='S&P 500', legend=False, figsize=(14, 4), rot=0)
        ax.set_xlabel('')
        sns.despine()
        plt.show();

        scaler = MinMaxScaler()
        sp500_scaled = pd.Series(scaler.fit_transform(sp500).squeeze(), index=sp500.index)
        sp500_scaled.describe()

        def create_univariate_rnn_data(data, window_size):
            n = len(data)
            y = data[window_size:]
            data = data.values.reshape(-1, 1) # make 2D
            X = np.hstack(tuple([data[i: n-j, :] for i, j in enumerate(range(window_size, 0, -1))]))
            return pd.DataFrame(X, index=y.index), y

        window_size = 63
        X, y = create_univariate_rnn_data(sp500_scaled, window_size=window_size)

        X_train = X[:'2018'].values.reshape(-1, window_size, 1)
        y_train = y[:'2018']
        # keep the last year for testing
        X_test = X['2019':'2020'].values.reshape(-1, window_size, 1)
        y_test = y['2019':'2020']

        n_obs, window_size, n_features = X_train.shape

        rnn = Sequential([
            LSTM(units=10, 
            input_shape=(window_size, n_features), name='LSTM'),
            Dense(1, name='Output')
            ])

        print(rnn.summary())

        optimizer = keras.optimizers.RMSprop(
            lr=0.001,
            rho=0.9,
            epsilon=1e-08,
            decay=0.0
            )

        rnn.compile(loss='mean_squared_error', optimizer=optimizer)

        rnn_path = (results_path / 'rnn.h5').as_posix()
        checkpointer = ModelCheckpoint(
            filepath=rnn_path, 
            verbose=1,
            monitor='val_loss',
            save_best_only=True
            )

        early_stopping = EarlyStopping(
            monitor='val_loss', 
            patience=20,
            restore_best_weights=True
            )

        lstm_training = rnn.fit(
            X_train,
            y_train,
            epochs=150,
            batch_size=20,
            shuffle=True,
            validation_data=(X_test, y_test),
            callbacks=[early_stopping, checkpointer],
            verbose=1
            )

        fig, ax = plt.subplots(figsize=(12, 4))
        loss_history = pd.DataFrame(lstm_training.history).pow(.5)
        loss_history.index += 1
        best_rmse = loss_history.val_loss.min()
        best_epoch = loss_history.val_loss.idxmin()
        title = f'5-Epoch Rolling RMSE (Best Validation RMSE: {best_rmse:.4%})'
        loss_history.columns=['Training RMSE', 'Validation RMSE']
        loss_history.rolling(5).mean().plot(logy=True, lw=2, title=title, ax=ax)
        ax.axvline(best_epoch, ls='--', lw=1, c='k')
        sns.despine()
        fig.tight_layout()
        # fig.savefig(results_path / 'rnn_sp500_error', dpi=300)
        plt.show()

        train_rmse_scaled = np.sqrt(rnn.evaluate(X_train, y_train, verbose=0))
        test_rmse_scaled = np.sqrt(rnn.evaluate(X_test, y_test, verbose=0))
        print(f'Train RMSE: {train_rmse_scaled:.4f} | Test RMSE: {test_rmse_scaled:.4f}')

        train_predict_scaled = rnn.predict(X_train)
        test_predict_scaled = rnn.predict(X_test)

        train_ic = spearmanr(y_train, train_predict_scaled)[0]
        test_ic = spearmanr(y_test, test_predict_scaled)[0]
        print(f'Train IC: {train_ic:.4f} | Test IC: {test_ic:.4f}')

        train_predict = pd.Series(scaler.inverse_transform(train_predict_scaled).squeeze(), index=y_train.index)
        test_predict = (pd.Series(scaler.inverse_transform(test_predict_scaled).squeeze(), index=y_test.index))

        y_train_rescaled = scaler.inverse_transform(y_train.to_frame()).squeeze()
        y_test_rescaled = scaler.inverse_transform(y_test.to_frame()).squeeze()

        train_rmse = np.sqrt(mean_squared_error(train_predict, y_train_rescaled))
        test_rmse = np.sqrt(mean_squared_error(test_predict, y_test_rescaled))
        f'Train RMSE: {train_rmse:.2f} | Test RMSE: {test_rmse:.2f}'

        sp500['Train Predictions'] = train_predict
        sp500['Test Predictions'] = test_predict
        sp500 = sp500.join(train_predict.to_frame(
            'predictions').assign(
                data='Train').append(test_predict.to_frame(
                    'predictions').assign(data='Test'))
                    )

        fig=plt.figure(figsize=(14,7))
        ax1 = plt.subplot(221)
        sp500.loc['2015':, 'SP500'].plot(lw=4, ax=ax1, c='k')
        sp500.loc['2015':, ['Test Predictions', 'Train Predictions']].plot(lw=2, ax=ax1, ls='--')
        ax1.set_title('In- and Out-of-sample Predictions')
        with sns.axes_style("white"):
            ax3 = plt.subplot(223)
            sns.scatterplot(x='SP500', y='predictions', data=sp500, hue='data', ax=ax3)
            ax3.text(x=.02, y=.95, s=f'Test IC ={test_ic:.2%}', transform=ax3.transAxes)
            ax3.text(x=.02, y=.87, s=f'Train IC={train_ic:.2%}', transform=ax3.transAxes)
            ax3.set_title('Correlation')
            ax3.legend(loc='lower right')
            ax2 = plt.subplot(222)
            ax4 = plt.subplot(224, sharex = ax2, sharey=ax2)
            sns.distplot(train_predict.squeeze()- y_train_rescaled, ax=ax2)
            ax2.set_title('Train Error')
            ax2.text(x=.03, y=.92, s=f'Train RMSE ={train_rmse:.4f}', transform=ax2.transAxes)
            sns.distplot(test_predict.squeeze()-y_test_rescaled, ax=ax4)
            ax4.set_title('Test Error')
            ax4.text(x=.03, y=.92, s=f'Test RMSE ={test_rmse:.4f}', transform=ax4.transAxes)
        sns.despine()
        fig.tight_layout()
        plt.show()
        # fig.savefig(results_path / 'rnn_sp500_regression', dpi=300);

if __name__ == '__main__':
    ticker = '^GSPC'
    # run = Univariate_TS_Reg(ticker)
    # run.runs()